{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "T-kZ9XJ3Q4d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount( '/content/drive', force_remount=True )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhHekEy2BjV3",
        "outputId": "9c27f3e7-9bb9-4393-c4c8-7444f852c6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBKHDP4bCktm",
        "outputId": "c7533947-c666-4787-88fb-89fbe17caf5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IMagenet'...\n",
            "remote: Enumerating objects: 120594, done.\u001b[K\n",
            "remote: Total 120594 (delta 0), reused 0 (delta 0), pack-reused 120594\u001b[K\n",
            "Receiving objects: 100% (120594/120594), 212.68 MiB | 33.40 MiB/s, done.\n",
            "Resolving deltas: 100% (1115/1115), done.\n",
            "Checking out files: 100% (120206/120206), done.\n",
            "test  train  val  wnids.txt  words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for line in open('/content/IMagenet/tiny-imagenet-200/val/val_annotations.txt'):\n",
        "  img_name, label = line.split('\\t')[:2]\n",
        "  dest = '/content/IMagenet/tiny-imagenet-200/valid/'+label\n",
        "  os.makedirs(dest, exist_ok=True)\n",
        "  shutil.copy('/content/IMagenet/tiny-imagenet-200/val/images/'+img_name,os.path.join(dest,img_name))"
      ],
      "metadata": {
        "id": "xKAKWkpvHG8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 128\n",
        "target_size = (85, 85)\n",
        "\n",
        "train_datagen = ImageDataGenerator()\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/IMagenet/tiny-imagenet-200/train',  \n",
        "        target_size=target_size,  \n",
        "        batch_size=batch_size,\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical')  \n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/IMagenet/tiny-imagenet-200/valid',\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJmBRfTrYEcl",
        "outputId": "f306eddc-c566-427b-e1cc-774dd9bff520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet**"
      ],
      "metadata": {
        "id": "OONhp1qxXGLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_Resnet = tf.keras.applications.resnet50.ResNet50(weights='imagenet'\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_Resnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au8zDka1L2JJ",
        "outputId": "e3a82664-0412-4d25-f854-f07b32df7445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "94781440/94765736 [==============================] - 0s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 85, 85, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 91, 91, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 43, 43, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 43, 43, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 43, 43, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 45, 45, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 22, 22, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 22, 22, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 22, 22, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 22, 22, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 22, 22, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 22, 22, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 22, 22, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 22, 22, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 22, 22, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 22, 22, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 22, 22, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 22, 22, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 22, 22, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 22, 22, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 22, 22, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 22, 22, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 22, 22, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 11, 11, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 11, 11, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 11, 11, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 11, 11, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 11, 11, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 11, 11, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 11, 11, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 11, 11, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 11, 11, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 6, 6, 256)    131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 6, 6, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                                                  'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block1_out[0][0]',       \n",
            "                                                                  'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block2_out[0][0]',       \n",
            "                                                                  'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block3_out[0][0]',       \n",
            "                                                                  'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block4_out[0][0]',       \n",
            "                                                                  'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block5_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block5_out[0][0]',       \n",
            "                                                                  'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block6_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 3, 3, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 3, 3, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 3, 3, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 3, 3, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 3, 3, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 3, 3, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 3, 3, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 3, 3, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 3, 3, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 3, 3, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 3, 3, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 3, 3, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 3, 3, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 3, 3, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 3, 3, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 3, 3, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in feature_extractor_Resnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "feature_extractor_Resnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1L2A2DkZYKQ",
        "outputId": "1a0d29b5-7945-47bc-d1d5-5f842ce33100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 85, 85, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 91, 91, 3)    0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 43, 43, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 43, 43, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 43, 43, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 45, 45, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 22, 22, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 22, 22, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 22, 22, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 22, 22, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 22, 22, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 22, 22, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 22, 22, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 22, 22, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 22, 22, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 22, 22, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 22, 22, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 22, 22, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 22, 22, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 22, 22, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 22, 22, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 22, 22, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 22, 22, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 11, 11, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 11, 11, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 11, 11, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 11, 11, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 11, 11, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 11, 11, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 11, 11, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 11, 11, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 11, 11, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 6, 6, 256)    131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 6, 6, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                                                  'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block1_out[0][0]',       \n",
            "                                                                  'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block2_out[0][0]',       \n",
            "                                                                  'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block3_out[0][0]',       \n",
            "                                                                  'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block4_out[0][0]',       \n",
            "                                                                  'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block5_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block5_out[0][0]',       \n",
            "                                                                  'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block6_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 3, 3, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 3, 3, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 3, 3, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 3, 3, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 3, 3, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 3, 3, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 3, 3, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 3, 3, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 3, 3, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 3, 3, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 3, 3, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 3, 3, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 3, 3, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 3, 3, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 3, 3, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 3, 3, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten"
      ],
      "metadata": {
        "id": "HRDG8dS-aH-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_Resnet(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9otjFU6bBrj",
        "outputId": "df6951ff-84e9-44ea-dc0d-7f3f5cf6cd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 85, 85, 3)]       0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 3, 3, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 18432)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               3686600   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,274,312\n",
            "Trainable params: 3,686,600\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "kW4oZ3dBbK9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator,\n",
        "                    epochs = 10,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrwJ6wg2bR3u",
        "outputId": "02611650-f402-4885-9ecf-5779202978d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 91s 100ms/step - loss: 8.7984 - acc: 0.2770 - val_loss: 9.2778 - val_acc: 0.3253\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 74s 95ms/step - loss: 4.0994 - acc: 0.5499 - val_loss: 10.2509 - val_acc: 0.3274\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 75s 95ms/step - loss: 2.5125 - acc: 0.6787 - val_loss: 10.5688 - val_acc: 0.3521\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 74s 95ms/step - loss: 1.7173 - acc: 0.7611 - val_loss: 11.6636 - val_acc: 0.3532\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 74s 95ms/step - loss: 1.4690 - acc: 0.7987 - val_loss: 12.6928 - val_acc: 0.3607\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 74s 95ms/step - loss: 1.2652 - acc: 0.8281 - val_loss: 13.5292 - val_acc: 0.3697\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 1.1480 - acc: 0.8492 - val_loss: 14.8242 - val_acc: 0.3687\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 75s 95ms/step - loss: 1.0110 - acc: 0.8699 - val_loss: 16.1773 - val_acc: 0.3552\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 75s 95ms/step - loss: 0.9465 - acc: 0.8796 - val_loss: 16.8054 - val_acc: 0.3665\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 75s 95ms/step - loss: 0.8985 - acc: 0.8901 - val_loss: 18.2013 - val_acc: 0.3614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PLtrn-jscK6-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "411c44e6-327e-4ede-ba09-0c9bb159fdf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator.classes"
      ],
      "metadata": {
        "id": "78aYjpy9Pd9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)"
      ],
      "metadata": {
        "id": "Wn_37PK7VRfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "TcsI7FxpQ3UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_valid_Resnet = model.predict(validation_generator)"
      ],
      "metadata": {
        "id": "HznM6oItWCXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_Resnet.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjFGv1A_RVaC",
        "outputId": "bcd72ad4-fe4c-438e-c89b-586a755a9729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.76      0.56        50\n",
            "           1       0.58      0.58      0.58        50\n",
            "           2       0.18      0.12      0.14        50\n",
            "           3       0.19      0.18      0.19        50\n",
            "           4       0.35      0.30      0.32        50\n",
            "           5       0.24      0.10      0.14        50\n",
            "           6       0.93      0.28      0.43        50\n",
            "           7       0.19      0.14      0.16        50\n",
            "           8       0.58      0.56      0.57        50\n",
            "           9       0.31      0.36      0.33        50\n",
            "          10       0.85      0.22      0.35        50\n",
            "          11       0.45      0.28      0.35        50\n",
            "          12       0.70      0.42      0.53        50\n",
            "          13       0.57      0.72      0.64        50\n",
            "          14       0.59      0.74      0.65        50\n",
            "          15       0.70      0.14      0.23        50\n",
            "          16       0.08      0.46      0.13        50\n",
            "          17       0.58      0.44      0.50        50\n",
            "          18       0.35      0.16      0.22        50\n",
            "          19       0.37      0.48      0.42        50\n",
            "          20       0.59      0.38      0.46        50\n",
            "          21       0.55      0.44      0.49        50\n",
            "          22       0.72      0.52      0.60        50\n",
            "          23       0.64      0.72      0.68        50\n",
            "          24       0.10      0.28      0.14        50\n",
            "          25       0.54      0.30      0.38        50\n",
            "          26       0.42      0.20      0.27        50\n",
            "          27       0.26      0.10      0.14        50\n",
            "          28       0.35      0.24      0.29        50\n",
            "          29       0.17      0.30      0.22        50\n",
            "          30       0.20      0.10      0.13        50\n",
            "          31       0.26      0.44      0.33        50\n",
            "          32       0.32      0.18      0.23        50\n",
            "          33       0.23      0.22      0.23        50\n",
            "          34       0.31      0.38      0.34        50\n",
            "          35       0.19      0.66      0.30        50\n",
            "          36       0.34      0.54      0.42        50\n",
            "          37       0.48      0.26      0.34        50\n",
            "          38       0.43      0.40      0.41        50\n",
            "          39       0.53      0.36      0.43        50\n",
            "          40       0.35      0.18      0.24        50\n",
            "          41       0.16      0.26      0.20        50\n",
            "          42       0.32      0.44      0.37        50\n",
            "          43       0.75      0.24      0.36        50\n",
            "          44       0.87      0.52      0.65        50\n",
            "          45       0.70      0.46      0.55        50\n",
            "          46       0.44      0.30      0.36        50\n",
            "          47       0.54      0.38      0.45        50\n",
            "          48       0.14      0.18      0.16        50\n",
            "          49       0.14      0.30      0.19        50\n",
            "          50       0.55      0.32      0.41        50\n",
            "          51       0.21      0.24      0.22        50\n",
            "          52       0.65      0.44      0.52        50\n",
            "          53       0.43      0.24      0.31        50\n",
            "          54       0.21      0.34      0.26        50\n",
            "          55       0.50      0.32      0.39        50\n",
            "          56       0.24      0.34      0.28        50\n",
            "          57       0.48      0.44      0.46        50\n",
            "          58       0.67      0.24      0.35        50\n",
            "          59       0.32      0.40      0.36        50\n",
            "          60       0.67      0.40      0.50        50\n",
            "          61       0.59      0.44      0.51        50\n",
            "          62       0.34      0.30      0.32        50\n",
            "          63       0.36      0.40      0.38        50\n",
            "          64       0.27      0.24      0.25        50\n",
            "          65       0.19      0.32      0.24        50\n",
            "          66       0.95      0.36      0.52        50\n",
            "          67       0.37      0.20      0.26        50\n",
            "          68       0.45      0.42      0.43        50\n",
            "          69       0.28      0.22      0.25        50\n",
            "          70       0.30      0.44      0.36        50\n",
            "          71       0.63      0.48      0.55        50\n",
            "          72       0.24      0.54      0.33        50\n",
            "          73       0.79      0.30      0.43        50\n",
            "          74       0.39      0.22      0.28        50\n",
            "          75       0.23      0.36      0.28        50\n",
            "          76       0.53      0.42      0.47        50\n",
            "          77       0.18      0.24      0.21        50\n",
            "          78       0.61      0.72      0.66        50\n",
            "          79       0.21      0.34      0.26        50\n",
            "          80       0.24      0.24      0.24        50\n",
            "          81       0.86      0.72      0.78        50\n",
            "          82       0.41      0.26      0.32        50\n",
            "          83       0.50      0.22      0.31        50\n",
            "          84       0.21      0.26      0.23        50\n",
            "          85       0.49      0.40      0.44        50\n",
            "          86       0.32      0.58      0.41        50\n",
            "          87       0.68      0.26      0.38        50\n",
            "          88       0.13      0.12      0.12        50\n",
            "          89       0.20      0.60      0.30        50\n",
            "          90       0.79      0.52      0.63        50\n",
            "          91       0.71      0.44      0.54        50\n",
            "          92       0.62      0.36      0.46        50\n",
            "          93       0.70      0.14      0.23        50\n",
            "          94       0.44      0.30      0.36        50\n",
            "          95       0.31      0.38      0.34        50\n",
            "          96       0.23      0.60      0.33        50\n",
            "          97       0.32      0.24      0.27        50\n",
            "          98       0.50      0.20      0.29        50\n",
            "          99       0.18      0.20      0.19        50\n",
            "         100       0.31      0.20      0.24        50\n",
            "         101       0.48      0.40      0.43        50\n",
            "         102       0.33      0.28      0.30        50\n",
            "         103       0.49      0.84      0.62        50\n",
            "         104       0.50      0.38      0.43        50\n",
            "         105       0.41      0.22      0.29        50\n",
            "         106       0.29      0.26      0.27        50\n",
            "         107       0.50      0.54      0.52        50\n",
            "         108       0.73      0.44      0.55        50\n",
            "         109       0.75      0.42      0.54        50\n",
            "         110       0.59      0.20      0.30        50\n",
            "         111       0.33      0.50      0.40        50\n",
            "         112       0.36      0.08      0.13        50\n",
            "         113       0.77      0.40      0.53        50\n",
            "         114       0.53      0.18      0.27        50\n",
            "         115       0.96      0.50      0.66        50\n",
            "         116       0.29      0.26      0.27        50\n",
            "         117       0.67      0.24      0.35        50\n",
            "         118       0.53      0.58      0.55        50\n",
            "         119       0.40      0.04      0.07        50\n",
            "         120       0.19      0.16      0.17        50\n",
            "         121       0.31      0.66      0.42        50\n",
            "         122       0.12      0.20      0.15        50\n",
            "         123       0.19      0.22      0.21        50\n",
            "         124       0.76      0.64      0.70        50\n",
            "         125       0.27      0.36      0.31        50\n",
            "         126       0.37      0.64      0.47        50\n",
            "         127       0.31      0.50      0.38        50\n",
            "         128       0.32      0.52      0.40        50\n",
            "         129       0.44      0.56      0.49        50\n",
            "         130       0.44      0.32      0.37        50\n",
            "         131       0.14      0.12      0.13        50\n",
            "         132       0.30      0.16      0.21        50\n",
            "         133       0.80      0.48      0.60        50\n",
            "         134       0.64      0.46      0.53        50\n",
            "         135       0.26      0.38      0.31        50\n",
            "         136       0.50      0.14      0.22        50\n",
            "         137       0.30      0.40      0.34        50\n",
            "         138       0.44      0.16      0.24        50\n",
            "         139       0.21      0.16      0.18        50\n",
            "         140       0.89      0.16      0.27        50\n",
            "         141       0.38      0.52      0.44        50\n",
            "         142       0.35      0.38      0.36        50\n",
            "         143       0.64      0.64      0.64        50\n",
            "         144       0.46      0.26      0.33        50\n",
            "         145       0.60      0.60      0.60        50\n",
            "         146       0.85      0.44      0.58        50\n",
            "         147       0.13      0.64      0.22        50\n",
            "         148       0.27      0.26      0.26        50\n",
            "         149       0.39      0.52      0.44        50\n",
            "         150       0.10      0.42      0.17        50\n",
            "         151       0.20      0.30      0.24        50\n",
            "         152       0.49      0.50      0.50        50\n",
            "         153       0.50      0.20      0.29        50\n",
            "         154       0.92      0.22      0.35        50\n",
            "         155       0.25      0.60      0.35        50\n",
            "         156       0.32      0.16      0.21        50\n",
            "         157       0.45      0.10      0.16        50\n",
            "         158       0.29      0.14      0.19        50\n",
            "         159       0.07      0.12      0.09        50\n",
            "         160       0.38      0.50      0.43        50\n",
            "         161       0.31      0.36      0.33        50\n",
            "         162       0.38      0.54      0.44        50\n",
            "         163       0.49      0.42      0.45        50\n",
            "         164       0.60      0.30      0.40        50\n",
            "         165       1.00      0.40      0.57        50\n",
            "         166       0.81      0.44      0.57        50\n",
            "         167       0.62      0.36      0.46        50\n",
            "         168       0.09      0.12      0.10        50\n",
            "         169       0.44      0.14      0.21        50\n",
            "         170       0.67      0.24      0.35        50\n",
            "         171       0.41      0.48      0.44        50\n",
            "         172       0.34      0.20      0.25        50\n",
            "         173       0.61      0.50      0.55        50\n",
            "         174       0.49      0.48      0.48        50\n",
            "         175       0.18      0.04      0.07        50\n",
            "         176       0.52      0.66      0.58        50\n",
            "         177       0.28      0.46      0.35        50\n",
            "         178       0.50      0.42      0.46        50\n",
            "         179       0.35      0.12      0.18        50\n",
            "         180       0.18      0.22      0.20        50\n",
            "         181       0.50      0.38      0.43        50\n",
            "         182       0.35      0.12      0.18        50\n",
            "         183       0.34      0.58      0.43        50\n",
            "         184       0.51      0.48      0.49        50\n",
            "         185       0.52      0.48      0.50        50\n",
            "         186       0.62      0.32      0.42        50\n",
            "         187       0.41      0.56      0.47        50\n",
            "         188       0.65      0.26      0.37        50\n",
            "         189       0.44      0.62      0.51        50\n",
            "         190       0.33      0.28      0.30        50\n",
            "         191       0.88      0.58      0.70        50\n",
            "         192       0.58      0.42      0.49        50\n",
            "         193       0.76      0.74      0.75        50\n",
            "         194       0.45      0.48      0.47        50\n",
            "         195       0.33      0.28      0.30        50\n",
            "         196       0.57      0.24      0.34        50\n",
            "         197       0.25      0.36      0.29        50\n",
            "         198       0.45      0.58      0.50        50\n",
            "         199       0.45      0.30      0.36        50\n",
            "\n",
            "    accuracy                           0.36     10000\n",
            "   macro avg       0.44      0.36      0.37     10000\n",
            "weighted avg       0.44      0.36      0.37     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_Resnet.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98d0wks8Rt6P",
        "outputId": "c80a6df7-d1fa-421e-ba19-ab9acf3bb51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[38  0  0 ...  0  0  0]\n",
            " [ 0 29  0 ...  0  0  0]\n",
            " [ 0  2  6 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 18  5  0]\n",
            " [ 0  0  0 ...  5 29  0]\n",
            " [ 0  0  0 ...  0  0 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 128\n",
        "target_size = (85, 85)\n",
        "\n",
        "train_datagen2 = ImageDataGenerator( rotation_range=10,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.1,\n",
        "                                    zoom_range=0.1,\n",
        "                                    channel_shift_range=0.0,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip=True,\n",
        "                                    rescale=1./255)\n",
        "\n",
        "test_datagen2 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator2 = train_datagen2.flow_from_directory(\n",
        "        '/content/IMagenet/tiny-imagenet-200/train',  \n",
        "        target_size=target_size,  \n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  \n",
        "\n",
        "validation_generator2 = test_datagen2.flow_from_directory(\n",
        "        '/content/IMagenet/tiny-imagenet-200/valid',\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZUmJ6KUCk4c",
        "outputId": "104a2053-9e0f-4bd6-b670-b5fa5177d088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resnet without transfer learning**"
      ],
      "metadata": {
        "id": "d4ZvmtcVkZCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_Resnet = tf.keras.applications.resnet50.ResNet50(weights=None\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_Resnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8UgZWD0kZCo",
        "outputId": "fd5d337f-00fd-4592-e35a-ab808d92624b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 85, 85, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 91, 91, 3)    0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 43, 43, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 43, 43, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 43, 43, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 45, 45, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 22, 22, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 22, 22, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 22, 22, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 22, 22, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 22, 22, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 22, 22, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 22, 22, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 22, 22, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 22, 22, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 22, 22, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 22, 22, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 22, 22, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 22, 22, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 22, 22, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 22, 22, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 22, 22, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 22, 22, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 22, 22, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 22, 22, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 22, 22, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 11, 11, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 11, 11, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 11, 11, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 11, 11, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 11, 11, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 11, 11, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 11, 11, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 11, 11, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 11, 11, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 11, 11, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 11, 11, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 11, 11, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 11, 11, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 11, 11, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 11, 11, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 6, 6, 256)    131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 6, 6, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                                                  'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block1_out[0][0]',       \n",
            "                                                                  'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block2_out[0][0]',       \n",
            "                                                                  'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block3_out[0][0]',       \n",
            "                                                                  'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block4_out[0][0]',       \n",
            "                                                                  'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block5_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 6, 6, 256)    262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 6, 6, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 6, 6, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 6, 6, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 6, 6, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 6, 6, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 6, 6, 1024)   0           ['conv4_block5_out[0][0]',       \n",
            "                                                                  'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 6, 6, 1024)   0           ['conv4_block6_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 3, 3, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 3, 3, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 3, 3, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 3, 3, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 3, 3, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 3, 3, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 3, 3, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 3, 3, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 3, 3, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 3, 3, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 3, 3, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 3, 3, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 3, 3, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 3, 3, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 3, 3, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 3, 3, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 3, 3, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 3, 3, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 3, 3, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_Resnet(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGVp-VxlkZCo",
        "outputId": "f41edd82-b5c3-4add-d523-e818c2c3c994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 85, 85, 3)]       0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 3, 3, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 18432)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 200)               3686600   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 27,274,312\n",
            "Trainable params: 27,221,192\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "Z0RKyeY_kZCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator,\n",
        "                    epochs = 10,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChiyyESskZCo",
        "outputId": "186a7d37-4825-4b5c-a03a-85be7aa11026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 234s 290ms/step - loss: 5.2717 - acc: 0.0552 - val_loss: 4.5103 - val_acc: 0.0898\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 3.8576 - acc: 0.1666 - val_loss: 5.9357 - val_acc: 0.1308\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 3.3114 - acc: 0.2527 - val_loss: 4.2761 - val_acc: 0.1860\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 2.9036 - acc: 0.3250 - val_loss: 3.9582 - val_acc: 0.1962\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 226s 288ms/step - loss: 2.5124 - acc: 0.3959 - val_loss: 7.0794 - val_acc: 0.1887\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 226s 288ms/step - loss: 2.1037 - acc: 0.4767 - val_loss: 5.1515 - val_acc: 0.2493\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 1.5801 - acc: 0.5899 - val_loss: 7.2899 - val_acc: 0.2634\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 0.9886 - acc: 0.7337 - val_loss: 5.3216 - val_acc: 0.2432\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 0.5324 - acc: 0.8525 - val_loss: 18.3515 - val_acc: 0.2526\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 225s 288ms/step - loss: 0.3616 - acc: 0.8982 - val_loss: 48.7343 - val_acc: 0.2201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "uRgebtlJkZCp",
        "outputId": "1f19964f-109f-4b6e-cba7-7093e929d386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_resnet = model.predict(validation_generator)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_resnet.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWdWK4d3kZCp",
        "outputId": "6abc10b5-0309-418a-f340-6575a47ca8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.50      0.56        50\n",
            "           1       0.72      0.36      0.48        50\n",
            "           2       0.34      0.20      0.25        50\n",
            "           3       0.25      0.08      0.12        50\n",
            "           4       0.21      0.14      0.17        50\n",
            "           5       0.09      0.08      0.09        50\n",
            "           6       0.78      0.14      0.24        50\n",
            "           7       0.21      0.10      0.14        50\n",
            "           8       0.74      0.40      0.52        50\n",
            "           9       0.13      0.10      0.11        50\n",
            "          10       0.18      0.06      0.09        50\n",
            "          11       0.27      0.34      0.30        50\n",
            "          12       0.39      0.28      0.33        50\n",
            "          13       0.42      0.10      0.16        50\n",
            "          14       0.50      0.18      0.26        50\n",
            "          15       0.46      0.12      0.19        50\n",
            "          16       0.00      0.00      0.00        50\n",
            "          17       0.67      0.16      0.26        50\n",
            "          18       0.19      0.20      0.20        50\n",
            "          19       0.44      0.24      0.31        50\n",
            "          20       0.33      0.26      0.29        50\n",
            "          21       0.73      0.32      0.44        50\n",
            "          22       0.59      0.34      0.43        50\n",
            "          23       0.53      0.16      0.25        50\n",
            "          24       0.08      0.04      0.05        50\n",
            "          25       0.26      0.16      0.20        50\n",
            "          26       0.15      0.10      0.12        50\n",
            "          27       0.00      0.00      0.00        50\n",
            "          28       0.18      0.20      0.19        50\n",
            "          29       0.02      0.04      0.03        50\n",
            "          30       0.12      0.14      0.13        50\n",
            "          31       0.53      0.20      0.29        50\n",
            "          32       0.04      0.04      0.04        50\n",
            "          33       0.09      0.10      0.10        50\n",
            "          34       0.27      0.36      0.31        50\n",
            "          35       0.18      0.30      0.23        50\n",
            "          36       0.75      0.48      0.59        50\n",
            "          37       0.35      0.18      0.24        50\n",
            "          38       0.48      0.32      0.39        50\n",
            "          39       0.23      0.14      0.18        50\n",
            "          40       0.31      0.10      0.15        50\n",
            "          41       0.25      0.06      0.10        50\n",
            "          42       0.29      0.18      0.22        50\n",
            "          43       0.38      0.22      0.28        50\n",
            "          44       0.69      0.54      0.61        50\n",
            "          45       0.56      0.50      0.53        50\n",
            "          46       0.30      0.12      0.17        50\n",
            "          47       0.53      0.16      0.25        50\n",
            "          48       0.06      0.10      0.08        50\n",
            "          49       0.09      0.10      0.10        50\n",
            "          50       0.46      0.36      0.40        50\n",
            "          51       0.14      0.20      0.16        50\n",
            "          52       0.22      0.52      0.31        50\n",
            "          53       0.38      0.30      0.33        50\n",
            "          54       0.33      0.18      0.23        50\n",
            "          55       0.16      0.46      0.24        50\n",
            "          56       0.08      0.14      0.10        50\n",
            "          57       0.23      0.36      0.28        50\n",
            "          58       0.64      0.28      0.39        50\n",
            "          59       0.10      0.18      0.13        50\n",
            "          60       0.34      0.28      0.31        50\n",
            "          61       0.22      0.54      0.31        50\n",
            "          62       0.04      0.14      0.07        50\n",
            "          63       0.20      0.28      0.23        50\n",
            "          64       0.05      0.06      0.05        50\n",
            "          65       0.10      0.20      0.13        50\n",
            "          66       0.28      0.24      0.26        50\n",
            "          67       0.11      0.16      0.13        50\n",
            "          68       0.24      0.28      0.26        50\n",
            "          69       0.20      0.20      0.20        50\n",
            "          70       0.28      0.10      0.15        50\n",
            "          71       0.28      0.22      0.25        50\n",
            "          72       0.14      0.14      0.14        50\n",
            "          73       0.16      0.14      0.15        50\n",
            "          74       0.27      0.24      0.26        50\n",
            "          75       0.09      0.10      0.09        50\n",
            "          76       0.07      0.08      0.07        50\n",
            "          77       0.12      0.10      0.11        50\n",
            "          78       0.33      0.56      0.41        50\n",
            "          79       0.17      0.08      0.11        50\n",
            "          80       0.08      0.04      0.05        50\n",
            "          81       0.54      0.58      0.56        50\n",
            "          82       0.20      0.34      0.25        50\n",
            "          83       0.24      0.20      0.22        50\n",
            "          84       0.10      0.10      0.10        50\n",
            "          85       0.18      0.12      0.14        50\n",
            "          86       0.15      0.18      0.17        50\n",
            "          87       0.27      0.08      0.12        50\n",
            "          88       0.06      0.04      0.05        50\n",
            "          89       0.29      0.26      0.27        50\n",
            "          90       0.56      0.18      0.27        50\n",
            "          91       0.27      0.36      0.31        50\n",
            "          92       0.24      0.16      0.19        50\n",
            "          93       0.22      0.48      0.30        50\n",
            "          94       0.44      0.22      0.29        50\n",
            "          95       0.16      0.18      0.17        50\n",
            "          96       0.18      0.18      0.18        50\n",
            "          97       0.24      0.22      0.23        50\n",
            "          98       0.33      0.38      0.35        50\n",
            "          99       0.11      0.10      0.10        50\n",
            "         100       0.08      0.10      0.09        50\n",
            "         101       0.12      0.08      0.10        50\n",
            "         102       0.21      0.20      0.21        50\n",
            "         103       0.62      0.60      0.61        50\n",
            "         104       0.13      0.06      0.08        50\n",
            "         105       0.09      0.12      0.11        50\n",
            "         106       0.20      0.08      0.11        50\n",
            "         107       0.60      0.42      0.49        50\n",
            "         108       0.53      0.16      0.25        50\n",
            "         109       0.15      0.12      0.13        50\n",
            "         110       0.39      0.14      0.21        50\n",
            "         111       0.17      0.60      0.27        50\n",
            "         112       0.18      0.20      0.19        50\n",
            "         113       0.17      0.20      0.19        50\n",
            "         114       0.20      0.16      0.18        50\n",
            "         115       0.72      0.56      0.63        50\n",
            "         116       0.21      0.32      0.26        50\n",
            "         117       0.62      0.16      0.25        50\n",
            "         118       0.53      0.32      0.40        50\n",
            "         119       0.09      0.08      0.09        50\n",
            "         120       0.09      0.14      0.11        50\n",
            "         121       0.30      0.26      0.28        50\n",
            "         122       0.20      0.04      0.07        50\n",
            "         123       0.09      0.14      0.11        50\n",
            "         124       0.49      0.36      0.41        50\n",
            "         125       0.12      0.26      0.16        50\n",
            "         126       0.38      0.32      0.35        50\n",
            "         127       0.15      0.16      0.15        50\n",
            "         128       0.14      0.34      0.20        50\n",
            "         129       0.16      0.46      0.24        50\n",
            "         130       0.16      0.10      0.12        50\n",
            "         131       0.00      0.00      0.00        50\n",
            "         132       0.04      0.10      0.06        50\n",
            "         133       0.42      0.56      0.48        50\n",
            "         134       0.42      0.10      0.16        50\n",
            "         135       0.08      0.10      0.09        50\n",
            "         136       0.12      0.16      0.14        50\n",
            "         137       0.10      0.12      0.11        50\n",
            "         138       0.11      0.08      0.09        50\n",
            "         139       0.13      0.14      0.14        50\n",
            "         140       0.12      0.20      0.15        50\n",
            "         141       0.14      0.02      0.04        50\n",
            "         142       0.27      0.20      0.23        50\n",
            "         143       0.64      0.58      0.61        50\n",
            "         144       0.24      0.10      0.14        50\n",
            "         145       0.43      0.62      0.51        50\n",
            "         146       0.14      0.58      0.23        50\n",
            "         147       0.17      0.30      0.21        50\n",
            "         148       0.18      0.10      0.13        50\n",
            "         149       0.58      0.14      0.23        50\n",
            "         150       0.30      0.20      0.24        50\n",
            "         151       0.43      0.06      0.11        50\n",
            "         152       0.29      0.12      0.17        50\n",
            "         153       0.29      0.32      0.30        50\n",
            "         154       0.16      0.18      0.17        50\n",
            "         155       0.36      0.18      0.24        50\n",
            "         156       0.10      0.04      0.06        50\n",
            "         157       0.25      0.10      0.14        50\n",
            "         158       0.20      0.20      0.20        50\n",
            "         159       0.09      0.02      0.03        50\n",
            "         160       0.20      0.18      0.19        50\n",
            "         161       0.15      0.14      0.14        50\n",
            "         162       0.25      0.12      0.16        50\n",
            "         163       0.25      0.26      0.25        50\n",
            "         164       0.23      0.26      0.25        50\n",
            "         165       0.15      0.64      0.25        50\n",
            "         166       0.48      0.50      0.49        50\n",
            "         167       0.18      0.40      0.25        50\n",
            "         168       0.05      0.06      0.05        50\n",
            "         169       0.16      0.34      0.22        50\n",
            "         170       0.30      0.30      0.30        50\n",
            "         171       0.23      0.42      0.29        50\n",
            "         172       0.01      0.06      0.01        50\n",
            "         173       0.28      0.22      0.24        50\n",
            "         174       0.23      0.20      0.21        50\n",
            "         175       0.12      0.06      0.08        50\n",
            "         176       0.48      0.52      0.50        50\n",
            "         177       0.31      0.24      0.27        50\n",
            "         178       0.45      0.34      0.39        50\n",
            "         179       0.04      0.10      0.05        50\n",
            "         180       0.19      0.12      0.15        50\n",
            "         181       0.17      0.18      0.17        50\n",
            "         182       0.33      0.10      0.15        50\n",
            "         183       0.22      0.22      0.22        50\n",
            "         184       0.49      0.38      0.43        50\n",
            "         185       0.33      0.36      0.35        50\n",
            "         186       0.38      0.44      0.41        50\n",
            "         187       0.28      0.20      0.23        50\n",
            "         188       0.43      0.06      0.11        50\n",
            "         189       0.61      0.22      0.32        50\n",
            "         190       0.35      0.16      0.22        50\n",
            "         191       0.42      0.66      0.51        50\n",
            "         192       0.27      0.16      0.20        50\n",
            "         193       0.80      0.48      0.60        50\n",
            "         194       0.18      0.18      0.18        50\n",
            "         195       0.42      0.10      0.16        50\n",
            "         196       0.32      0.14      0.19        50\n",
            "         197       0.17      0.14      0.15        50\n",
            "         198       0.24      0.16      0.19        50\n",
            "         199       0.21      0.06      0.09        50\n",
            "\n",
            "    accuracy                           0.22     10000\n",
            "   macro avg       0.27      0.22      0.22     10000\n",
            "weighted avg       0.27      0.22      0.22     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_resnet.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKmzWD_kkZCp",
        "outputId": "6562f1ff-da16-4981-e3ef-7a97ecacde7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[25  0  0 ...  0  0  0]\n",
            " [ 0 18  0 ...  0  0  1]\n",
            " [ 0  0 10 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  7  1  0]\n",
            " [ 1  0  0 ...  2  8  0]\n",
            " [ 0  0  0 ...  0  0  3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten"
      ],
      "metadata": {
        "id": "WSEHvysPb8eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inception v3**"
      ],
      "metadata": {
        "id": "OOnEIgdWIchI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_Inception_v3 = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet'\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_Inception_v3.summary()"
      ],
      "metadata": {
        "id": "2ZQL6leazGnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in feature_extractor_Inception_v3.layers[0:-2]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "faf2a8zA_iCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_Inception_v3(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hjPVHihAP33",
        "outputId": "1eaa8032-b6a1-43e1-8c99-39ce4b495566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 85, 85, 3)]       0         \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 1, 1, 2048)        21802784  \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 200)               409800    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,212,584\n",
            "Trainable params: 409,800\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "NcnqAeGcAhKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 10,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "JkfP1s64Ao6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ZCI1GJQU0h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator2.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_inception = model.predict(validation_generator2)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_inception.argmax(axis=1))\n",
        "\n",
        "print(cls_report)\n",
        "\n"
      ],
      "metadata": {
        "id": "hP6Gj9GogOQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_inception.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "1X2V0l-ngse8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**inception without transfer learning**"
      ],
      "metadata": {
        "id": "0LZAIPF2h3t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_Inception_v3 = tf.keras.applications.efficientnet.EfficientNetB7(weights=None\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_Inception_v3.summary()"
      ],
      "metadata": {
        "id": "zaJrxAS1hWHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_Inception_v3(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "acBlcjTth8GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "mo_Y3wRGiJec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator,\n",
        "                    epochs = 7,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "_j6QcHtUisPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Efficientnet**"
      ],
      "metadata": {
        "id": "LiBYcI1OiRQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_efficientnet = tf.keras.applications.efficientnet.EfficientNetB7(weights='imagenet'\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_efficientnet.summary()"
      ],
      "metadata": {
        "id": "VFyCciVrhcXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in feature_extractor_efficientnet.layers[0:-2]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "_ljThxT5iqYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_efficientnet(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "z--Gn97Li4LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "1p4iNBwTjDY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator,\n",
        "                    epochs = 10,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "TTPFqsvqjLJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OjDTvgAVjWb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_efficientnet = model.predict(validation_generator)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_efficientnet.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "id": "AUVNLIW8uPNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_efficientnet.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "_cE5roDKunZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Efficientnet without transfer learning**"
      ],
      "metadata": {
        "id": "7V4v_WxsSxlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_efficientnet = tf.keras.applications.efficientnet.EfficientNetB7(weights=None\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_efficientnet.summary()"
      ],
      "metadata": {
        "id": "YwfpGPHlUs0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_efficientnet(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "MIY-BtUBYBls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "jJ5bOjY6YIqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 7,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "Z7OvebFkkO97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Densenet**"
      ],
      "metadata": {
        "id": "d8lWLbXEvoKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_dencenet = tf.keras.applications.DenseNet121(weights='imagenet'\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_dencenet.summary()"
      ],
      "metadata": {
        "id": "A1ytH4vGvl-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in feature_extractor_dencenet.layers[0:-2]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "O7Mj04hev36V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_dencenet(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "iCf8JXgzwEu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "tosHlftBwUVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 10,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "p45dhQjEwafe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3i9jMSAHwigC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_dencenet = model.predict(validation_generator2)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_dencenet.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "id": "m1-3xJaKF7YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_dencenet.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "-FMvsijPGJKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/hw3_model/dencenet/dencenet.h5')\n"
      ],
      "metadata": {
        "id": "LyvxsdMDGX9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dencenet without transfer learning**"
      ],
      "metadata": {
        "id": "Ly6DwuSaY9Ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_dencenet = tf.keras.applications.DenseNet121(weights=None\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_dencenet.summary()"
      ],
      "metadata": {
        "id": "g7HlfY5GYhRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_dencenet(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "FdDUH-rNZBcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "lH0ATb9pZJlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 7,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "srK_um5PZRBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2_UMEMQvZcPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_densenet = model.predict(validation_generator2)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_densenet.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "id": "zLslsxp6g5TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_densenet.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "tFJCfAvGhNBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mobile net**"
      ],
      "metadata": {
        "id": "zaTak9-lWSVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_Mobilenet = tf.keras.applications.MobileNetV2(weights='imagenet'\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_Mobilenet.summary()"
      ],
      "metadata": {
        "id": "oOPtG9MvbuHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in feature_extractor_Mobilenet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "feature_extractor_Mobilenet.summary()"
      ],
      "metadata": {
        "id": "od5g5uuRblcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten"
      ],
      "metadata": {
        "id": "gMKe6b4cyY11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_Mobilenet(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VHD3lMxZcHRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "Iw1zVQEycjr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 10,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "jYol-K57dIcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TYSWCfNvdTM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator2.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_Mobilenet = model.predict(validation_generator2)"
      ],
      "metadata": {
        "id": "dDhK9LDlr99K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_Mobilenet.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "id": "hMflWMh6suex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_Mobilenet.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "7T-XfZc9sqTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "wiq3l8BStdJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mobilenet withput transfer learning**"
      ],
      "metadata": {
        "id": "LfL5GP_uLzJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_Mobilenet = tf.keras.applications.MobileNetV2(weights=None\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_Mobilenet.summary()"
      ],
      "metadata": {
        "id": "aaWUhTcULyL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_Mobilenet(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7EYhEPQmL7TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "rB7TN1rIMOrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 10,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "ub-_aftqMDBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FMUJoK_IMQXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator2.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_mobilenet = model.predict(validation_generator2)"
      ],
      "metadata": {
        "id": "j_rzSai7VjrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_mobilenet.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "id": "Du9gFoVwV5qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_mobilenet.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "tg7Ax_RcWC_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG 19**"
      ],
      "metadata": {
        "id": "8SCNHfNvRZ-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_vgg19 = tf.keras.applications.vgg19.VGG19(weights='imagenet'\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_vgg19.summary()"
      ],
      "metadata": {
        "id": "DU_wdBZyAwsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in feature_extractor_vgg19.layers[0:-2]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "HuqyxnTHGth8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_vgg19(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n"
      ],
      "metadata": {
        "id": "N2Qp7HybHJlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "Tz9kr8PNHS9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 15,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "qbM8zds_HYvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_GyIcIIJHfvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator2.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_VGG19 = model.predict(validation_generator2)"
      ],
      "metadata": {
        "id": "t6a0byGIZM_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_VGG19.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "id": "1S0tLyScZYHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_VGG19.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "8V2azTNbZkF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG19 without transfer learning**"
      ],
      "metadata": {
        "id": "eHs4JpxVWqoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_vgg19 = tf.keras.applications.vgg19.VGG19(weights=None\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_vgg19.summary()"
      ],
      "metadata": {
        "id": "xD1KgGSLWOO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_vgg19(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)\n"
      ],
      "metadata": {
        "id": "BrRKxuMkXErB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "6l4bG7FMXI7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 7,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "lvnEC6xpXSR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U5BEZDSTXZEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator2.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_vgg19 = model.predict(validation_generator2)"
      ],
      "metadata": {
        "id": "tDZUYUnsi668"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_vgg19.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "id": "jMzPnbsrjD_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_vgg19.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "je-FdND_jI9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Xception**"
      ],
      "metadata": {
        "id": "w75o-MCqoPCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_Xception = tf.keras.applications.Xception(weights='imagenet'\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_Xception.summary()"
      ],
      "metadata": {
        "id": "LTgN-8XlaJ82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in feature_extractor_Xception.layers[0:-2]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "N-4e0V27ogSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_Xception(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)"
      ],
      "metadata": {
        "id": "z53wYE_dooMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "xyPibkH6owlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 15,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "wav0tFejo2Ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S_KrAyRQo7t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator2.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_xception = model.predict(validation_generator2)"
      ],
      "metadata": {
        "id": "JJabOlCN7W_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_xception.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "id": "nR8xfPaA7cR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_xception.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "s0JwPgOM9asS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Xception without transfer learning**"
      ],
      "metadata": {
        "id": "4EhDAzjsEKaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_Xception = tf.keras.applications.Xception(weights=None\n",
        "                                      , input_shape=(85, 85, 3) ,include_top=False)\n",
        "feature_extractor_Xception.summary()"
      ],
      "metadata": {
        "id": "hX9XgTVo-Pr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_layer = Input(shape = (85, 85, 3))\n",
        "features = feature_extractor_Xception(inp_layer)\n",
        "flat = Flatten()(features)\n",
        "output = Dense(units = 200, activation = 'softmax')(flat)\n",
        "\n",
        "model = Model(inputs = inp_layer, outputs = output)"
      ],
      "metadata": {
        "id": "n0vEZI-b-fKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(learning_rate = 0.001)\n",
        "BCE = categorical_crossentropy\n",
        "model.compile(optimizer = opt, loss=BCE, metrics = 'acc')"
      ],
      "metadata": {
        "id": "asGfxDLG-mD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_generator2,\n",
        "                    epochs = 10,\n",
        "                    validation_data=validation_generator2)"
      ],
      "metadata": {
        "id": "-HMMWFWL-rLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "train_loss = results.history['loss']\n",
        "val_loss = results.history['val_loss']\n",
        "train_acc = results.history['acc']\n",
        "val_acc = results.history['val_acc']\n",
        "\n",
        "plt.subplots(figsize=(10, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.semilogy(train_loss)\n",
        "plt.semilogy(val_loss)\n",
        "\n",
        "plt.legend(['training loss', 'validation loss'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('BCE')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "\n",
        "plt.legend(['training accuracy', 'validation accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Z8TXmTW-v1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = validation_generator2.classes\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_hat = to_categorical(y_hat,num_classes = 200)\n",
        "\n",
        "y_pred_valid_xception = model.predict(validation_generator2)"
      ],
      "metadata": {
        "id": "aRuTb6P2JBXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cls_report = classification_report(y_hat.argmax(axis=1), y_pred_valid_xception.argmax(axis=1))\n",
        "\n",
        "print(cls_report)"
      ],
      "metadata": {
        "id": "0GuwO8PQJOA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cnf = confusion_matrix(y_hat.argmax(axis=1), y_pred_valid_xception.argmax(axis=1))\n",
        "print(cnf)"
      ],
      "metadata": {
        "id": "pJV9Kk4kLAB6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}