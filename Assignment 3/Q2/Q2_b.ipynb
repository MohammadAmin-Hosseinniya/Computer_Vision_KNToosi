{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2_b.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "8GeGEpwvC7v1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UzsXHWvNDGqJ"
      },
      "outputs": [],
      "source": [
        "accuracy = np.zeros((1,6))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fZPr1yFNMslb",
        "outputId": "916d1568-30dc-44be-8ca9-6a92ad4c2a0b"
      },
      "source": [
        "for i in range(6):\n",
        "  from keras.datasets import cifar10\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "  inp_layer = Input(shape = (32, 32, 3))\n",
        "  conv1 = Conv2D(filters = 32, kernel_size=(5, 5), strides = (1, 1), padding = 'same',activation = 'relu')(inp_layer)\n",
        "  maxp1 = MaxPooling2D(pool_size=(2, 2), strides = (2, 2))(conv1)\n",
        "  for t in range(i):\n",
        "    conv1 = Conv2D(filters = 32, kernel_size=(5, 5), strides = (1, 1), padding = 'same',activation = 'relu')(maxp1)\n",
        "    maxp1 = MaxPooling2D(pool_size=(2, 2), strides = (2, 2))(conv1)\n",
        "  flat = tf.keras.layers.GlobalAveragePooling2D()(maxp1)\n",
        "  output = Dense(units = 10, activation = 'softmax')(flat)\n",
        "\n",
        "  Model1 = Model(inputs = inp_layer, outputs = output)\n",
        "\n",
        "  opt = Adam(learning_rate=0.001)\n",
        "  loss = categorical_crossentropy\n",
        "  Model1.compile(optimizer=opt, loss = loss, metrics = 'acc')\n",
        "\n",
        "  y_train = to_categorical(y_train, num_classes = 10)\n",
        "  y_test = to_categorical(y_test, num_classes = 10)\n",
        "  x_train = x_train.reshape((50000, 32, 32, 3))\n",
        "  x_test = x_test.reshape((10000, 32, 32, 3))\n",
        "\n",
        "  results_1 = Model1.fit(x_train, y_train,\n",
        "                      batch_size=32,\n",
        "                      epochs = 10,\n",
        "                      validation_data=(x_test, y_test))\n",
        "\n",
        "  accuracy[0][i] = results_1.history['val_acc'][-1]\n",
        "print(accuracy)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "170508288/170498071 [==============================] - 6s 0us/step\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 2.7390 - acc: 0.2507 - val_loss: 1.7643 - val_acc: 0.3654\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.7657 - acc: 0.3640 - val_loss: 1.6414 - val_acc: 0.4206\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.6965 - acc: 0.3911 - val_loss: 1.6562 - val_acc: 0.3892\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.6555 - acc: 0.4053 - val_loss: 1.5969 - val_acc: 0.4298\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.6096 - acc: 0.4233 - val_loss: 1.5786 - val_acc: 0.4171\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.5744 - acc: 0.4351 - val_loss: 1.5968 - val_acc: 0.4269\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.5536 - acc: 0.4476 - val_loss: 1.5329 - val_acc: 0.4513\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.5295 - acc: 0.4552 - val_loss: 1.5310 - val_acc: 0.4493\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.5168 - acc: 0.4615 - val_loss: 1.5750 - val_acc: 0.4358\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.5031 - acc: 0.4686 - val_loss: 1.4520 - val_acc: 0.4860\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 89s 56ms/step - loss: 2.0985 - acc: 0.3388 - val_loss: 1.6974 - val_acc: 0.3827\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 1.4834 - acc: 0.4717 - val_loss: 1.3993 - val_acc: 0.5074\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 1.3672 - acc: 0.5150 - val_loss: 1.2817 - val_acc: 0.5445\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 1.2836 - acc: 0.5493 - val_loss: 1.3398 - val_acc: 0.5229\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 1.2166 - acc: 0.5730 - val_loss: 1.2337 - val_acc: 0.5713\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 1.1623 - acc: 0.5899 - val_loss: 1.1881 - val_acc: 0.5890\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 1.1092 - acc: 0.6135 - val_loss: 1.1386 - val_acc: 0.6042\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 88s 57ms/step - loss: 1.0731 - acc: 0.6235 - val_loss: 1.1261 - val_acc: 0.6121\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 1.0468 - acc: 0.6342 - val_loss: 1.1276 - val_acc: 0.6127\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 89s 57ms/step - loss: 1.0230 - acc: 0.6436 - val_loss: 1.0714 - val_acc: 0.6289\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 101s 64ms/step - loss: 1.7734 - acc: 0.3763 - val_loss: 1.4792 - val_acc: 0.4596\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 100s 64ms/step - loss: 1.3967 - acc: 0.4973 - val_loss: 1.3190 - val_acc: 0.5313\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 100s 64ms/step - loss: 1.2599 - acc: 0.5539 - val_loss: 1.3436 - val_acc: 0.5291\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 100s 64ms/step - loss: 1.1425 - acc: 0.5978 - val_loss: 1.1590 - val_acc: 0.5883\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 99s 63ms/step - loss: 1.0512 - acc: 0.6322 - val_loss: 1.0983 - val_acc: 0.6163\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 99s 63ms/step - loss: 0.9883 - acc: 0.6550 - val_loss: 1.1216 - val_acc: 0.6148\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 99s 63ms/step - loss: 0.9380 - acc: 0.6739 - val_loss: 1.1247 - val_acc: 0.6098\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 99s 64ms/step - loss: 0.8904 - acc: 0.6887 - val_loss: 1.0391 - val_acc: 0.6439\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 99s 64ms/step - loss: 0.8432 - acc: 0.7075 - val_loss: 1.0976 - val_acc: 0.6365\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 100s 64ms/step - loss: 0.8153 - acc: 0.7139 - val_loss: 1.1210 - val_acc: 0.6319\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 104s 66ms/step - loss: 1.7694 - acc: 0.3741 - val_loss: 1.4669 - val_acc: 0.4693\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.4346 - acc: 0.4845 - val_loss: 1.3647 - val_acc: 0.5079\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.3274 - acc: 0.5269 - val_loss: 1.3042 - val_acc: 0.5367\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 104s 66ms/step - loss: 1.2322 - acc: 0.5623 - val_loss: 1.2487 - val_acc: 0.5618\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 104s 66ms/step - loss: 1.1567 - acc: 0.5882 - val_loss: 1.2301 - val_acc: 0.5686\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 104s 66ms/step - loss: 1.0959 - acc: 0.6107 - val_loss: 1.1709 - val_acc: 0.5948\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 104s 66ms/step - loss: 1.0517 - acc: 0.6287 - val_loss: 1.2052 - val_acc: 0.5905\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.0054 - acc: 0.6410 - val_loss: 1.1371 - val_acc: 0.6052\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 0.9553 - acc: 0.6630 - val_loss: 1.1317 - val_acc: 0.6111\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 0.9135 - acc: 0.6773 - val_loss: 1.0997 - val_acc: 0.6229\n",
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.6670 - acc: 0.3924 - val_loss: 1.4145 - val_acc: 0.4895\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.3723 - acc: 0.5114 - val_loss: 1.3196 - val_acc: 0.5315\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.2489 - acc: 0.5584 - val_loss: 1.2475 - val_acc: 0.5676\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.1612 - acc: 0.5905 - val_loss: 1.2096 - val_acc: 0.5797\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 104s 67ms/step - loss: 1.0913 - acc: 0.6179 - val_loss: 1.1596 - val_acc: 0.6007\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 1.0284 - acc: 0.6389 - val_loss: 1.1210 - val_acc: 0.6176\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 0.9818 - acc: 0.6571 - val_loss: 1.0675 - val_acc: 0.6411\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 0.9391 - acc: 0.6721 - val_loss: 1.0921 - val_acc: 0.6298\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 0.8950 - acc: 0.6902 - val_loss: 1.0988 - val_acc: 0.6439\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 105s 67ms/step - loss: 0.8604 - acc: 0.7015 - val_loss: 1.0600 - val_acc: 0.6471\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fbe5454b2dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmaxp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   2011\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2013\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_20\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_20/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,32].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 1, 32), dtype=float32)"
          ]
        }
      ]
    }
  ]
}